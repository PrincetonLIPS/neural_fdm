# Real-time design of architectural simulations with differentiable mechanics and neural networks

_Code base for the [paper](https://arxiv.org/abs/2409.02606) published at ICLR 2025_

![Our trained model, deployed in Rhino3D](masonry_vault_cad_design.gif)

Designing mechanically efficient geometry for architectural structures like shells, towers, and bridges, is an expensive iterative process. Existing techniques for solving such inverse problems rely on traditional optimization methods, which are slow and computationally expensive, limiting iteration speed and design exploration. Neural networks would seem to offer a solution via data-driven amortized optimization, but they often require extensive fine-tuning and cannot ensure that important design criteria, such as mechanical integrity, are met.

In this work, we combine neural networks with a differentiable mechanics simulator to develop a model that accelerates the solution of shape approximation problems for architectural structures represented as bar systems. This model explicitly guarantees compliance with mechanical constraints while generating designs that closely match target geometries. We validate our approach in two tasks, the design of masonry shells and cable-net towers. Our model achieves better accuracy and generalization than fully neural alternatives, and comparable accuracy to direct optimization but in real time, enabling fast and reliable design exploration. We further demonstrate its advantages by integrating it into 3D modeling software and fabricating a physical prototype.

Our work opens up new opportunities for accelerated mechanical design enhanced by neural networks for the built environment.

## Installation

_We only support installation on a CPU. Our paper does not use any GPUs. Crazy, right?_

Create a new [Anaconda](https://www.anaconda.com/) environment and then activate it:

```bash
conda create -n neural
conda activate neural
```

Install some dependencies from `pip`-land:

```bash
pip install --upgrade jax==0.4.23
pip install optax==0.1.5 equinox==0.11.3
pip install seaborn
```

Next, install COMPAS and COMPAS VIEW2 via `conda`. Please mind the version of these dependencies:

```bash
conda install -c conda-forge compas<2.0 compas_view2==0.7.0 
```

Finally, clone and install this repository from source:

```bash
git clone https://github.com/arpastrana/neural_fdm.git
cd neural_fdm
pip install -e .
```
Now, go ahead and play. Rock and roll ðŸŽ¸! 


## Play

This repository contains two folders with the meat of our work: `src` and `scripts`.
The first folder, `src`, defines all the code infrastructure we need to build, train, serialize, and visualize our model and the baselines.
The second one, `scripts`, groups a list of routines to execute the code in `src`, and more importantly, to reproduce our experiments at inference time.
With the scripts, you can even tesselate and 3D print your own masonry vault from one of our model predictions if you fancy!

### Configuration files

Our work focuses on two structural design tasks: compression-only shells and cablenet towers.
We thus create a `.yml` file with all the configuration hyperparameters per task.
The files are stored in the `scripts` folder as `bezier.yml` and `tower.yml` for the first and the second task, respectively.
The hyperparameters exposed in the configuration files range from choosing a data generator, prescribing the model architecture, and the optimization scheme.
We'll be mingling with them to steer the wheel while we run experiments.


### Data generation

An advantage of our work is that we only need to define target shapes alone, without a vector of force densities to be paired as ground-truth labels.
That would be the case in a fully supervised setting, which is not the case here.
Our model figures these labels out automatically.
This allows us to generate a dataset of target shapes on the fly at train time by specifying a `generator` configuration and a random `seed` to create pseudo-random keys.

#### Shells
The target shell shapes are parametrized by a square Bezier patch.

- `name`: The name of the generator to instantiate. One of `bezier_symmetric_double`, `bezier_symmetric`, `bezier_asymmetric`, and `bezier_lerp`. The first two options constraint the shapes to be symmetric along two or one axis, respectively. The third option does not enforce symmetry. The last option, `bezier_lerp` is used to interpolate linearnly a batch of doubly-symmetric and asymmetric shapes (i.e., shapes generated by `bezier_symmetric_double` and `bezier_asymmetric`).
- `num_points`: the number of control points that parametrize the Bezier patch.
- `bounds`: It specifies how to wiggle the control points of the patch on a `num_points x num_points` grid. The option `pillow` only moves the internal control point up and down, while `dome` additionally jitters the two control points on the boundary in and out. `saddle` is an extension of `dome` in that it lets one of the control points on the boundary move up and down too.
- `num_uv`: The number of spans to evaluate on the Bezier along the *u* and *v* directions. A value of `10`, for example, would result in a `10x10` grid of target points. These are the points to be matched during training.
- `size`: The length of the sides of the patch. It defines the scale of the task.
- `lerp_factor`: A scalar factor in [0, 1] to interpolate between two target surfaces. Only employed for `bezier_lerp`.

#### Towers
The target tower shapes are described in turn by a vertical sequence of planar circles.
The tower rings are deformed and rotated depending on the generator `name` and `bounds`.

- `name`: The generator name. Use `tower_ellipse` to make target shapes with elliptical rings, and `tower_circles` to keep the rings as circles.
- `bounds`: Either `straight` or `twisted`. The former scales the rings on the plane at random. The latter scales and rotates the rings randomly.
- `height`: The tower height.
- `radius`: The start radius of the all the generated circles.
- `num_sides`: The number of segments to discretize each circle with.
- `num_levels`: The number of circles to create along the tower's height. Equidistantly spaced.
- `num_rings`: The number of circles to be morphed during training. Must be `>2` since two of these rings are by defult the top and bottom circles of the tower.

### Building a model

We specify the architecture of a model in the configuration file, which for the most part, ressembles an autoencoder.
The configuration scheme is the same for any task.

#### Neural networks

Our experiments use multilayer perceptrons (MLP) for the encoder that maps shapes to simulation parameters, although we are by no means restricted to that.
An MLP too serves as a decoder for our fully neural baselines.
We employ one of the simplest possible neural networks, the MLP, to quantify the benefits of having a physics simulator in a neural network in large-scale mechanical design tasks.
This sets a baseline from which we can build upon with beefier architectures like graph neural networks, transformers, and beyond.

The encoder hyperparameters are:
- `shift`: The lower bound shift in output of the last layer of the encoder. This is precisely what we call `tau` in the paper.
- `hidden_layer_size`: The width of every fully-connected hidden layer. 
- `hidden_layer_num`: The number of hidden layers, output layer inclusive.
- `activation_fn_name`: The name of the activation function after each hidden layer.
- `final_activation_fn_name`: The activation function name after the output layer. We use `softplus` to ensure a strictly positive output, as needed by the simulator decoder.

The neural decoder's setup mirrors the encoder's, except for the `include_params_xl` flag. If set to `True`, then the decoder expects the latents and boundary conditions as inputs. Otherwise, it only decodes the latents. We fix this hyperparameter to `True` in the paper.

#### Simulator

For the simulator, the force density method (FDM), we only have `load` as a hyperparameter, which sets the magnitude of a vertical **area** load applied to the structures.
If this is nonzero, then the model will convert the area load into point loads to be compatible with our physics simulator.

### Training

We train our model and the baselines.
The training configuration 

### Testing

Blob.

### Direct optimization

Another baseline.

### Visualization

Blah.

## Citation

Consider citing our paper if this work was helpful to your research.
Don't worry, it's free.

```bibtex
@inproceedings{
    pastrana_2025_diffmechanics,
    title={Real-time design of architectural structures with differentiable mechanics and neural networks},
    author={Rafael Pastrana and Eder Medina and Isabel M. de Oliveira and Sigrid Adriaenssens and Ryan P Adams},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=Tpjq66xwTq}
}
```

## Contact

Reach out! If you have questions or find bugs in our code, please open an issue on Github or email the authors at arpastrana@princeton.edu. 